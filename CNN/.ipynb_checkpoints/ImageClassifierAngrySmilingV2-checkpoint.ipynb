{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers.legacy import RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "train_dir = pathlib.Path('/Users/alfahwun/Documents/faceexpression/train')\n",
    "val_dir = pathlib.Path('/Users/alfahwun/Documents/faceexpression/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7066\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(val_dir.glob('*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 48\n",
    "img_width = 48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 files belonging to 7 classes.\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 11:43:35.539894: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-07 11:43:35.539950: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=128,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7066 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=8,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alfahwun/miniforge3/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(lambda x,y: (x/255, y))\n",
    "val_ds = val_ds.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# 1 - Convolution\n",
    "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd Convolution layer\n",
    "model.add(Conv2D(128,(5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 4th Convolution layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(len(class_names), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 11:43:53.089917: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-07 11:43:53.091540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - ETA: 0s - loss: 1.9347 - accuracy: 0.2423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 11:45:39.683947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 120s 520ms/step - loss: 1.9347 - accuracy: 0.2423 - val_loss: 1.7693 - val_accuracy: 0.3046\n",
      "Epoch 2/50\n",
      "226/226 [==============================] - 105s 465ms/step - loss: 1.7574 - accuracy: 0.3062 - val_loss: 1.7263 - val_accuracy: 0.3122\n",
      "Epoch 3/50\n",
      "226/226 [==============================] - 111s 492ms/step - loss: 1.6527 - accuracy: 0.3568 - val_loss: 1.7169 - val_accuracy: 0.3472\n",
      "Epoch 4/50\n",
      "226/226 [==============================] - 122s 541ms/step - loss: 1.5849 - accuracy: 0.3866 - val_loss: 1.6093 - val_accuracy: 0.3892\n",
      "Epoch 5/50\n",
      "226/226 [==============================] - 122s 538ms/step - loss: 1.5270 - accuracy: 0.4093 - val_loss: 1.5560 - val_accuracy: 0.4111\n",
      "Epoch 6/50\n",
      "226/226 [==============================] - 126s 559ms/step - loss: 1.4788 - accuracy: 0.4291 - val_loss: 1.4698 - val_accuracy: 0.4353\n",
      "Epoch 7/50\n",
      "226/226 [==============================] - 118s 519ms/step - loss: 1.4297 - accuracy: 0.4491 - val_loss: 1.5653 - val_accuracy: 0.4224\n",
      "Epoch 8/50\n",
      "226/226 [==============================] - 115s 510ms/step - loss: 1.3896 - accuracy: 0.4669 - val_loss: 1.3896 - val_accuracy: 0.4735\n",
      "Epoch 9/50\n",
      "226/226 [==============================] - 117s 518ms/step - loss: 1.3471 - accuracy: 0.4848 - val_loss: 1.3476 - val_accuracy: 0.4912\n",
      "Epoch 10/50\n",
      "226/226 [==============================] - 118s 524ms/step - loss: 1.3106 - accuracy: 0.4940 - val_loss: 1.3306 - val_accuracy: 0.5023\n",
      "Epoch 11/50\n",
      "226/226 [==============================] - 121s 534ms/step - loss: 1.2856 - accuracy: 0.5071 - val_loss: 1.2912 - val_accuracy: 0.5089\n",
      "Epoch 12/50\n",
      "226/226 [==============================] - 130s 573ms/step - loss: 1.2518 - accuracy: 0.5231 - val_loss: 1.2698 - val_accuracy: 0.5192\n",
      "Epoch 13/50\n",
      "226/226 [==============================] - 132s 584ms/step - loss: 1.2250 - accuracy: 0.5323 - val_loss: 1.2436 - val_accuracy: 0.5337\n",
      "Epoch 14/50\n",
      "226/226 [==============================] - 119s 528ms/step - loss: 1.1976 - accuracy: 0.5423 - val_loss: 1.2269 - val_accuracy: 0.5357\n",
      "Epoch 15/50\n",
      "226/226 [==============================] - 114s 505ms/step - loss: 1.1714 - accuracy: 0.5546 - val_loss: 1.2411 - val_accuracy: 0.5423\n",
      "Epoch 16/50\n",
      "226/226 [==============================] - 103s 456ms/step - loss: 1.1476 - accuracy: 0.5648 - val_loss: 1.1892 - val_accuracy: 0.5521\n",
      "Epoch 17/50\n",
      "226/226 [==============================] - 104s 462ms/step - loss: 1.1323 - accuracy: 0.5712 - val_loss: 1.1615 - val_accuracy: 0.5664\n",
      "Epoch 18/50\n",
      "226/226 [==============================] - 111s 491ms/step - loss: 1.0985 - accuracy: 0.5812 - val_loss: 1.1625 - val_accuracy: 0.5669\n",
      "Epoch 19/50\n",
      "226/226 [==============================] - 125s 553ms/step - loss: 1.0771 - accuracy: 0.5919 - val_loss: 1.1728 - val_accuracy: 0.5644\n",
      "Epoch 20/50\n",
      "226/226 [==============================] - 97s 429ms/step - loss: 1.0566 - accuracy: 0.6014 - val_loss: 1.1358 - val_accuracy: 0.5777\n",
      "Epoch 21/50\n",
      "226/226 [==============================] - 63s 278ms/step - loss: 1.0393 - accuracy: 0.6082 - val_loss: 1.1692 - val_accuracy: 0.5658\n",
      "Epoch 22/50\n",
      "226/226 [==============================] - 66s 292ms/step - loss: 1.0096 - accuracy: 0.6202 - val_loss: 1.1379 - val_accuracy: 0.5826\n",
      "Epoch 23/50\n",
      "226/226 [==============================] - 66s 293ms/step - loss: 0.9908 - accuracy: 0.6251 - val_loss: 1.1373 - val_accuracy: 0.5815\n",
      "Epoch 24/50\n",
      "226/226 [==============================] - 68s 300ms/step - loss: 0.9650 - accuracy: 0.6365 - val_loss: 1.1200 - val_accuracy: 0.5822\n",
      "Epoch 25/50\n",
      "226/226 [==============================] - 69s 305ms/step - loss: 0.9503 - accuracy: 0.6449 - val_loss: 1.1246 - val_accuracy: 0.5875\n",
      "Epoch 26/50\n",
      "226/226 [==============================] - 69s 305ms/step - loss: 0.9220 - accuracy: 0.6571 - val_loss: 1.1418 - val_accuracy: 0.5817\n",
      "Epoch 27/50\n",
      "226/226 [==============================] - 111s 490ms/step - loss: 0.9007 - accuracy: 0.6620 - val_loss: 1.1096 - val_accuracy: 0.5991\n",
      "Epoch 28/50\n",
      "226/226 [==============================] - 102s 450ms/step - loss: 0.8865 - accuracy: 0.6644 - val_loss: 1.0986 - val_accuracy: 0.6039\n",
      "Epoch 29/50\n",
      "226/226 [==============================] - 94s 416ms/step - loss: 0.8605 - accuracy: 0.6810 - val_loss: 1.1235 - val_accuracy: 0.6008\n",
      "Epoch 30/50\n",
      "226/226 [==============================] - 97s 428ms/step - loss: 0.8388 - accuracy: 0.6845 - val_loss: 1.1170 - val_accuracy: 0.6091\n",
      "Epoch 31/50\n",
      "226/226 [==============================] - 85s 375ms/step - loss: 0.8170 - accuracy: 0.6954 - val_loss: 1.1282 - val_accuracy: 0.5960\n",
      "Epoch 32/50\n",
      "226/226 [==============================] - 92s 409ms/step - loss: 0.7950 - accuracy: 0.7044 - val_loss: 1.0901 - val_accuracy: 0.6155\n",
      "Epoch 33/50\n",
      "226/226 [==============================] - 113s 499ms/step - loss: 0.7723 - accuracy: 0.7134 - val_loss: 1.1483 - val_accuracy: 0.6071\n",
      "Epoch 34/50\n",
      "226/226 [==============================] - 117s 517ms/step - loss: 0.7534 - accuracy: 0.7187 - val_loss: 1.0893 - val_accuracy: 0.6233\n",
      "Epoch 35/50\n",
      "226/226 [==============================] - 102s 452ms/step - loss: 0.7246 - accuracy: 0.7324 - val_loss: 1.1459 - val_accuracy: 0.6090\n",
      "Epoch 36/50\n",
      "226/226 [==============================] - 86s 382ms/step - loss: 0.7056 - accuracy: 0.7367 - val_loss: 1.1484 - val_accuracy: 0.6066\n",
      "Epoch 37/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 50,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    \"/Users/alfahwun/Downloads/testimage.png\", target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
